{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Import user-defined packages\n",
    "from scripts.outlier_detector import OutlierDetector as old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data\n",
    "df = pd.read_csv(\"../../data/raw/data_train.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Inspect data\n",
    "# Note: Given that all features have 202944 non-null counts and the dataset has 202944 rows, it's likely that there are no null values present.\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1: Remove unused column(s)\n",
    "df.drop(\n",
    "    columns=[\"Id\"],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Step 3.2: Remove duplicate row(S)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle invalid datas (non numerical)\n",
    "\n",
    "# Convert all features to numeric\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Summarize invalid data per feature\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Feature scaling\n",
    "\n",
    "# # Min-max scaling is applied to maintain uniformity within the data range.\n",
    "# # Formular: X = (X - min) / (max - min)\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# columns_to_scale = [\"BMI\", \"ExtraMedTest\", \"ExtraAlcoholTest\", \"MentHlth\", \"PhysHlth\"]\n",
    "# df[columns_to_scale] = min_max_scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "# # Inspect data after scaling\n",
    "# df.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Handle Outliers\n",
    "\n",
    "# Grid initilization\n",
    "rows, cols = len(df.columns) // 4, 4\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, rows * 3))\n",
    "\n",
    "for i, (column, ax) in enumerate(zip(df.columns, axes.flatten())):\n",
    "    sns.boxplot(data=df[column], ax=ax)\n",
    "    ax.set_title(f\"KDE Plot of {column}\")\n",
    "    ax.set_xlabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Handle categorical data\n",
    "\n",
    "# Create one-hot encoding\n",
    "age_dummies = pd.get_dummies(df[\"Age\"]).astype(int)\n",
    "gen_health_dummies = pd.get_dummies(df[\"GenHlth\"]).astype(int)\n",
    "education_dummies = pd.get_dummies(df[\"Education\"]).astype(int)\n",
    "income_dummies = pd.get_dummies(df[\"Income\"]).astype(int)\n",
    "\n",
    "# Rename the columns\n",
    "gen_health_dummies.columns = [\n",
    "    \"Genhlth_1\",\n",
    "    \"Genhlth_2\",\n",
    "    \"Genhlth_3\",\n",
    "    \"Genhlth_4\",\n",
    "    \"Genhlth_5\",\n",
    "]\n",
    "\n",
    "age_dummies.columns = [\n",
    "    \"Age_18_24\",\n",
    "    \"Age_25_29\",\n",
    "    \"Age_30_34\",\n",
    "    \"Age_35_39\",\n",
    "    \"Age_40_44\",\n",
    "    \"Age_45_49\",\n",
    "    \"Age_50_54\",\n",
    "    \"Age_55_59\",\n",
    "    \"Age_60_64\",\n",
    "    \"Age_65_69\",\n",
    "    \"Age_70_74\",\n",
    "    \"Age_75_79\",\n",
    "    \"Age_80_or_older\",\n",
    "]\n",
    "\n",
    "education_dummies.columns = [\n",
    "    \"Educ_Never\",\n",
    "    \"Educ_G1_8\",\n",
    "    \"Educ_G9_11\",\n",
    "    \"Educ_G12_GED\",\n",
    "    \"Educ_Col_1_3\",\n",
    "    \"Educ_Col_4_more\",\n",
    "]\n",
    "\n",
    "income_dummies.columns = [\n",
    "    \"Inc_1\",\n",
    "    \"Inc_2\",\n",
    "    \"Inc_3\",\n",
    "    \"Inc_4\",\n",
    "    \"Inc_5\",\n",
    "    \"Inc_6\",\n",
    "    \"Inc_7\",\n",
    "    \"Inc_8\",\n",
    "]\n",
    "\n",
    "# Drop the original\n",
    "df.drop([\"Education\", \"Income\", \"Age\", \"GenHlth\"], axis=1, inplace=True)\n",
    "\n",
    "# Concatenate the original DataFrame\n",
    "df = pd.concat(\n",
    "    [df, age_dummies, gen_health_dummies, education_dummies, income_dummies], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/processed/data_train_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
