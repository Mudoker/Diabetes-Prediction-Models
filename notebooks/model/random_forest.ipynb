{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "### COSC2753 - Machine Learning\n",
    "\n",
    "# **Random Forrest**\n",
    "\n",
    "<center>────────────────────────────</center>\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules ['scripts.styler', 'scripts.neko', 'scripts.utils', 'scripts.outlier_detector'] not found. \n",
      "Recaching...\n",
      "┌──────────────────────────────────┐\n",
      "│  Validating Package Versions...  │\n",
      "└──────────────────────────────────┘\n",
      ">>> numpy is up to date: 1.26.4\n",
      ">>> pandas is up to date: 2.2.1\n",
      ">>> seaborn is up to date: 0.13.2\n",
      ">>> matplotlib is up to date: 3.8.3\n",
      ">>> tabulate is up to date: 0.9.0\n",
      ">>> sklearn is up to date: 1.4.1.post1\n",
      ">>> statsmodels is up to date: 0.14.1\n",
      ">>> imblearn is up to date: 0.12.2\n",
      "\u001b[1m\u001b[3m\n",
      "Done validating packages\n",
      "\u001b[0m\n",
      "┌───────────────────────────┐\n",
      "│  Initializing Project...  │\n",
      "└───────────────────────────┘\n",
      "\n",
      "    /\\_____/\\\n",
      "   /  x   o  \\\n",
      "  ( ==  ^  == )       Neko has arrived!\n",
      "   )         (        An data visualizing extension for analyzing DataFrames.\n",
      "  (           )       Art: https://www.asciiart.eu/animals/cats.\n",
      " ( (  )   (  ) )\n",
      "(__(__)___(__)__)\n",
      "\n",
      "\u001b[1m\u001b[3mDone initializing project...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Reload modules\n",
    "sys.path.append(\"../../\")  # Root directory\n",
    "modules_to_reload = [\n",
    "    \"scripts.styler\",\n",
    "    \"scripts.neko\",\n",
    "    \"scripts.utils\",\n",
    "    \"scripts.outlier_detector\",\n",
    "]\n",
    "\n",
    "# Reload modules if they have been modified\n",
    "missing_modules = []\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    else:\n",
    "        missing_modules.append(module_name)\n",
    "\n",
    "# Recache missing modules\n",
    "if missing_modules:\n",
    "    print(f\"Modules {missing_modules} not found. \\nRecaching...\")\n",
    "\n",
    "# Import user-defined scripts\n",
    "from scripts.styler import Styler\n",
    "from scripts.neko import Neko\n",
    "from scripts.utils import Utils\n",
    "from scripts.outlier_detector import OutlierDetector\n",
    "\n",
    "# Initialize styler\n",
    "styler = Styler()  # Text Styler\n",
    "\n",
    "# Check package versions\n",
    "styler.draw_box(\"Validating Package Versions...\")\n",
    "\n",
    "try:\n",
    "    with open(\"../../requirements.txt\", \"r\") as file:\n",
    "        requirements = file.readlines()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '../../requirements.txt' not found. Please check your directory!\")\n",
    "\n",
    "packages_to_check = [np, pd, sns, matplotlib, tabulate, sklearn, statsmodels, imblearn]\n",
    "\n",
    "for package in packages_to_check:\n",
    "    Utils.version_check(package, requirements=requirements)\n",
    "\n",
    "styled_text = styler.style(\"\\nDone validating packages\\n\", bold=True, italic=True)\n",
    "print(styled_text)\n",
    "\n",
    "# Initialize objects\n",
    "styler.draw_box(\"Initializing Project...\")\n",
    "neko = Neko()  # Panda extension\n",
    "bullet = \">>>\"  # Bullet point\n",
    "plt = matplotlib.pyplot  # Matplotlib\n",
    "\n",
    "# Configuration\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "styled_text = styler.style(\"Done initializing project...\", bold=True, italic=True)\n",
    "print(styled_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────┐\n",
      "│  Data Loaded Successfully  │\n",
      "└────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load data\n",
    "    df_train = pd.read_csv(\"../../data/processed/data_train_processed.csv\")\n",
    "    df_test = pd.read_csv(\"../../data/test/data_test.csv\")\n",
    "\n",
    "    styler.draw_box(\"Data Loaded Successfully\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For similar reasons to those underlying the decision tree selection, feature scaling and outlier handling will be **ignored** in the context of **tree-based methods**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df_train.drop(columns=[\"Status\"], axis=1)\n",
    "y = df_train[\"Status\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Model Evaluation (First Attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28473\n",
      "           1       1.00      1.00      1.00     28536\n",
      "\n",
      "    accuracy                           1.00     57009\n",
      "   macro avg       1.00      1.00      1.00     57009\n",
      "weighted avg       1.00      1.00      1.00     57009\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      7158\n",
      "           1       0.90      0.81      0.85      7095\n",
      "\n",
      "    accuracy                           0.86     14253\n",
      "   macro avg       0.86      0.86      0.86     14253\n",
      "weighted avg       0.86      0.86      0.86     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "neko.evaluate_model(rf_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────────────┐\n",
      "│  Training the model (With Reduced Features)  │\n",
      "└──────────────────────────────────────────────┘\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28473\n",
      "           1       1.00      1.00      1.00     28536\n",
      "\n",
      "    accuracy                           1.00     57009\n",
      "   macro avg       1.00      1.00      1.00     57009\n",
      "weighted avg       1.00      1.00      1.00     57009\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      7158\n",
      "           1       0.88      0.81      0.84      7095\n",
      "\n",
      "    accuracy                           0.85     14253\n",
      "   macro avg       0.85      0.85      0.85     14253\n",
      "weighted avg       0.85      0.85      0.85     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Traing the model (With reduced Features)\n",
    "styler.draw_box(\"Training the model (With Reduced Features)\")\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Drop the specified columns from X_train and X_test\n",
    "X_train_reduced = X_train.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "X_test_reduced = X_test.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "\n",
    "model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions\n",
    "neko.evaluate_model(model, X_train_reduced, y_train, X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis reveals results comparable to those achieved by a **Decision Tree model**. Excluding the two proposed columns for removal results in a decrease in the model's accuracy. Therefore, it is recommended to retain both columns.\n",
    "\n",
    "Furthermore, the same hyperparameter selection process used for pruning the **Decision Tree** to address overfitting will also be applied here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 150, 200, 225, 250, 300],  # Number of trees in the forest\n",
    "    \"max_depth\": [None] + list(range(10, 110, 10)),  # Maximum depth of the tree\n",
    "    \"min_samples_split\": np.arange(\n",
    "        5, 20, 2\n",
    "    ).tolist(),  # Minimum number of samples required to split an internal node\n",
    "    \"min_samples_leaf\": np.arange(\n",
    "        2, 6\n",
    "    ).tolist(),  # Minimum number of samples required to be at a leaf node\n",
    "    \"criterion\": [\"gini\", \"entropy\"],  # Function to measure the quality of a split\n",
    "    \"max_features\": [\n",
    "        None,\n",
    "        \"sqrt\",\n",
    "        \"log2\",\n",
    "    ],  # Number of features to consider when looking for the best split\n",
    "    \"ccp_alpha\": np.arange(\n",
    "        0.0, 0.1, 0.01\n",
    "    ),  # Complexity parameter used for Minimal Cost-Complexity Pruning\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 225, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 40, 'criterion': 'entropy', 'ccp_alpha': 0.0}\n",
      "Best Score: 0.8712939008589056\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier with 100 trees\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=clf,\n",
    "    param_distributions=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=5,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_iter=1, # Number of iterations (explained in the conclusion)\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best Parameters:\", search.best_params_)\n",
    "print(\"Best Score:\", search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "This model exhibits similar overall behavior to a decision tree. While tuning the model results in a slight accuracy improvement (approximately `1%`), there is a `6%` difference exists between the training and validation set accuracy. This difference is generally considered acceptable and not indicative of overfitting `[1]` `[2]`. It's important to note that hardware limitations necessitated a randomized search. However, research by S. Weiran `[3]` suggests a `96%` chance of finding the top `5%` parameters after `60` iterations, even with a randomized approach.\n",
    "\n",
    "[1] [Free Code Camp - What is Overfitting in Machine Learning? ](https://www.freecodecamp.org/news/what-is-overfitting-machine-learning/#:~:text=The%20accuracy%20gap%20is%20a,what%20you%20should%20look%20for.)\n",
    "\n",
    "[2] [Data Science - Ideal difference in the training accuracy and testing accuracy](https://datascience.stackexchange.com/questions/20256/ideal-difference-in-the-training-accuracy-and-testing-accuracy#:~:text=If%20test%20data%20starts%20decreasing%2C%20you%20have%20overfitting.&text=A%20difference%20of%205%25%20is%20fine.,and%20verify%20with%20mean%20accuracies.)\n",
    "\n",
    "[3] [Medium - Hyper Parameter Tuning with Randomised Grid Search\n",
    "](https://medium.com/m/global-identity-2?redirectUrl=https%3A%2F%2Ftowardsdatascience.com%2Fhyper-parameter-tuning-with-randomised-grid-search-54f865d27926)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
