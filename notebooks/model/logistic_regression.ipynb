{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "### COSC2753 - Machine Learning\n",
    "\n",
    "# **Logistic Regression**\n",
    "\n",
    "<center>────────────────────────────</center>\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────┐\n",
      "│  Checking Package Versions...  │\n",
      "└────────────────────────────────┘\n",
      ">>> numpy is up to date: 1.26.4\n",
      ">>> pandas is up to date: 2.2.1\n",
      ">>> seaborn is up to date: 0.13.2\n",
      ">>> matplotlib is up to date: 3.8.3\n",
      ">>> tabulate is up to date: 0.9.0\n",
      ">>> sklearn is up to date: 1.4.1.post1\n",
      ">>> statsmodels is up to date: 0.14.1\n",
      ">>> imblearn is up to date: 0.12.2\n",
      "\u001b[1m\u001b[3m\n",
      "Done checking packages version...\n",
      "\u001b[0m\n",
      "┌───────────────────────────┐\n",
      "│  Initializing Project...  │\n",
      "└───────────────────────────┘\n",
      "\n",
      "    /\\_____/\\\n",
      "   /  x   o  \\\n",
      "  ( ==  ^  == )       Neko has arrived!\n",
      "   )         (        An data visualizing extension for analyzing DataFrames.\n",
      "  (           )       Art: https://www.asciiart.eu/animals/cats.\n",
      " ( (  )   (  ) )\n",
      "(__(__)___(__)__)\n",
      "\n",
      "\u001b[1m\u001b[3mDone initializing project...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "import warnings\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Reload modules\n",
    "sys.path.append(\"../../\")  # Root directory\n",
    "modules_to_reload = [\n",
    "    \"scripts.styler\",\n",
    "    \"scripts.neko\",\n",
    "    \"scripts.utils\",\n",
    "]\n",
    "\n",
    "# Reload modules if they have been modified\n",
    "missing_modules = []\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    else:\n",
    "        missing_modules.append(module_name)\n",
    "\n",
    "# Recache missing modules\n",
    "if missing_modules:\n",
    "    print(f\"Modules {missing_modules} not found. \\nRecaching...\")\n",
    "\n",
    "# Import user-defined scripts\n",
    "from scripts.styler import Styler\n",
    "from scripts.neko import Neko\n",
    "from scripts.utils import Utils\n",
    "\n",
    "\n",
    "# Initialize styler\n",
    "styler = Styler()  # Text Styler\n",
    "\n",
    "# Check package versions\n",
    "styler.draw_box(\"Checking Package Versions...\")\n",
    "\n",
    "try:\n",
    "    with open(\"../../requirements.txt\", \"r\") as file:\n",
    "        requirements = file.readlines()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '../../requirements.txt' not found.\")\n",
    "\n",
    "packages_to_check = [np, pd, sns, matplotlib, tabulate, sklearn, statsmodels, imblearn]\n",
    "\n",
    "for package in packages_to_check:\n",
    "    Utils.version_check(package, requirements=requirements)\n",
    "\n",
    "styled_text = styler.style(\n",
    "    \"\\nDone checking packages version...\\n\", bold=True, italic=True\n",
    ")\n",
    "print(styled_text)\n",
    "\n",
    "# Initialize objects\n",
    "styler.draw_box(\"Initializing Project...\")\n",
    "neko = Neko()  # Panda extension\n",
    "bullet = \">>>\"  # Bullet point\n",
    "plt = matplotlib.pyplot  # Matplotlib\n",
    "\n",
    "# Configuration\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "styled_text = styler.style(\"Done initializing project...\", bold=True, italic=True)\n",
    "print(styled_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "metadata": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────┐\n",
      "│  Data Loaded Successfully  │\n",
      "└────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load data\n",
    "    df_train = pd.read_csv(\"../../data/processed/data_train_processed.csv\")\n",
    "    df_test = pd.read_csv(\"../../data/test/data_test.csv\")\n",
    "\n",
    "    styler.draw_box(\"Data Loaded Successfully\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333056 entries, 0 to 333055\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   HighBP                333056 non-null  int64  \n",
      " 1   HighChol              333056 non-null  int64  \n",
      " 2   CholCheck             333056 non-null  int64  \n",
      " 3   BMI                   333056 non-null  float64\n",
      " 4   Smoker                333056 non-null  int64  \n",
      " 5   Stroke                333056 non-null  int64  \n",
      " 6   HeartDiseaseorAttack  333056 non-null  int64  \n",
      " 7   PhysActivity          333056 non-null  int64  \n",
      " 8   Fruits                333056 non-null  int64  \n",
      " 9   Veggies               333056 non-null  int64  \n",
      " 10  HvyAlcoholConsump     333056 non-null  int64  \n",
      " 11  AnyHealthcare         333056 non-null  int64  \n",
      " 12  NoDocbcCost           333056 non-null  int64  \n",
      " 13  GenHlth               333056 non-null  int64  \n",
      " 14  MentHlth              333056 non-null  int64  \n",
      " 15  PhysHlth              333056 non-null  float64\n",
      " 16  DiffWalk              333056 non-null  int64  \n",
      " 17  Sex                   333056 non-null  int64  \n",
      " 18  Age                   333056 non-null  int64  \n",
      " 19  Education             333056 non-null  int64  \n",
      " 20  Income                333056 non-null  int64  \n",
      " 21  ExtraMedTest          333056 non-null  float64\n",
      " 22  ExtraAlcoholTest      333056 non-null  float64\n",
      " 23  Status                333056 non-null  int64  \n",
      "dtypes: float64(4), int64(20)\n",
      "memory usage: 61.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>ExtraMedTest</th>\n",
       "      <th>ExtraAlcoholTest</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-64.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>53.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-98.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0       0         0          1  24.0       1       0                     0   \n",
       "1       0         0          1  28.0       0       0                     0   \n",
       "2       0         0          1  36.0       1       0                     0   \n",
       "3       0         1          1  35.0       0       0                     0   \n",
       "4       0         1          1  27.0       0       0                     0   \n",
       "5       1         1          1  26.0       1       0                     1   \n",
       "6       0         0          0  34.0       0       0                     0   \n",
       "7       0         0          1  28.0       0       0                     0   \n",
       "8       0         1          1  33.0       1       0                     0   \n",
       "9       0         0          1  28.0       0       0                     0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  \\\n",
       "0             1       0        1                  0              1   \n",
       "1             1       1        1                  0              1   \n",
       "2             1       1        0                  0              1   \n",
       "3             1       1        1                  0              1   \n",
       "4             1       0        1                  0              1   \n",
       "5             1       0        1                  0              1   \n",
       "6             1       1        1                  0              1   \n",
       "7             1       1        1                  0              1   \n",
       "8             1       1        1                  0              1   \n",
       "9             1       1        1                  0              1   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  \\\n",
       "0            0        2         0       0.0         0    0    8          4   \n",
       "1            0        1         1       0.0         0    0    2          6   \n",
       "2            1        3         5       7.5         1    0    3          2   \n",
       "3            0        3         0       0.0         0    0    8          6   \n",
       "4            0        3         0       0.0         0    0    9          5   \n",
       "5            1        4         0       0.0         0    0   12          4   \n",
       "6            0        2         0       0.0         0    0    5          4   \n",
       "7            0        2         2       5.0         0    0    6          6   \n",
       "8            0        3         0       0.0         0    0    8          5   \n",
       "9            0        2         0       0.0         0    1    7          5   \n",
       "\n",
       "   Income  ExtraMedTest  ExtraAlcoholTest  Status  \n",
       "0       5          60.0             0.000       0  \n",
       "1       8           0.0           -64.000       0  \n",
       "2       1         -46.0             0.000       0  \n",
       "3       8         -83.0            -7.566       0  \n",
       "4       4         -58.0             0.000       0  \n",
       "5       6         -14.0            53.000       0  \n",
       "6       5           0.0            -2.000       0  \n",
       "7       8         -61.0           -98.000       0  \n",
       "8       7          70.0             0.000       0  \n",
       "9       8         -12.0             0.000       0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Techniques for Logistic Regression Models\n",
    "\n",
    "Logistic regression models often benefit from scaled features to enhance accuracy. When dealing with varied range numerical data, two common scaling techniques are **standardization** (using a *StandardScaler*) and **Normalisation** (using a *MinMaxScaler*).\n",
    "\n",
    "**Limitations of Log Transformation and StandardScaler:** \n",
    "The *StandardScaler*, which typically involves log transformation followed by standardization, might not be suitable for this specific case. This method can encounter issues when the data contains zeros or negative values, potentially leading to inaccurate transformations.\n",
    "\n",
    "Therefore, the *MinMaxScaler* is a more appropriate choice for this scenario. This technique effectively handles skewed data by rescaling each feature to a specific range (often 0 to 1). This ensures that all features contribute equally to the logistic regression model, improving its ability to learn the underlying relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>ExtraMedTest</th>\n",
       "      <th>ExtraAlcoholTest</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.000</td>\n",
       "      <td>334210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.459</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HighBP    HighChol   CholCheck         BMI      Smoker      Stroke  \\\n",
       "count  334210.000  334210.000  334210.000  334210.000  334210.000  334210.000   \n",
       "mean        0.459       0.421       0.967       0.555       0.379       0.029   \n",
       "std         0.498       0.494       0.179       0.206       0.485       0.167   \n",
       "min         0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "25%         0.000       0.000       1.000       0.411       0.000       0.000   \n",
       "50%         0.000       0.000       1.000       0.518       0.000       0.000   \n",
       "75%         1.000       1.000       1.000       0.687       1.000       0.000   \n",
       "max         1.000       1.000       1.000       1.000       1.000       1.000   \n",
       "\n",
       "       HeartDiseaseorAttack  PhysActivity      Fruits     Veggies  \\\n",
       "count            334210.000    334210.000  334210.000  334210.000   \n",
       "mean                  0.079         0.654       0.542       0.740   \n",
       "std                   0.269         0.476       0.498       0.439   \n",
       "min                   0.000         0.000       0.000       0.000   \n",
       "25%                   0.000         0.000       0.000       0.000   \n",
       "50%                   0.000         1.000       1.000       1.000   \n",
       "75%                   0.000         1.000       1.000       1.000   \n",
       "max                   1.000         1.000       1.000       1.000   \n",
       "\n",
       "       HvyAlcoholConsump  AnyHealthcare  NoDocbcCost     GenHlth    MentHlth  \\\n",
       "count         334210.000     334210.000   334210.000  334210.000  334210.000   \n",
       "mean               0.035          0.942        0.058       0.403       0.235   \n",
       "std                0.183          0.234        0.234       0.261       0.390   \n",
       "min                0.000          0.000        0.000       0.000       0.000   \n",
       "25%                0.000          1.000        0.000       0.250       0.000   \n",
       "50%                0.000          1.000        0.000       0.500       0.000   \n",
       "75%                0.000          1.000        0.000       0.500       0.400   \n",
       "max                1.000          1.000        1.000       1.000       1.000   \n",
       "\n",
       "         PhysHlth    DiffWalk         Sex         Age   Education      Income  \\\n",
       "count  334210.000  334210.000  334210.000  334210.000  334210.000  334210.000   \n",
       "mean        0.290       0.171       0.367       0.608       0.771       0.672   \n",
       "std         0.408       0.376       0.482       0.236       0.201       0.304   \n",
       "min         0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "25%         0.000       0.000       0.000       0.500       0.600       0.429   \n",
       "50%         0.000       0.000       0.000       0.667       0.800       0.714   \n",
       "75%         0.667       0.000       1.000       0.750       1.000       1.000   \n",
       "max         1.000       1.000       1.000       1.000       1.000       1.000   \n",
       "\n",
       "       ExtraMedTest  ExtraAlcoholTest    Status  \n",
       "count    334210.000        334210.000  334210.0  \n",
       "mean          0.572             0.574       0.5  \n",
       "std           0.277             0.274       0.5  \n",
       "min           0.000             0.000       0.0  \n",
       "25%           0.461             0.464       0.0  \n",
       "50%           0.500             0.503       0.5  \n",
       "75%           0.812             0.809       1.0  \n",
       "max           1.000             1.000       1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale features using min-max scaler (Normalization)\n",
    "df_train = neko.scale_feature(df_train, \"norm\")\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df_train.drop(columns=[\"Status\"], axis=1)\n",
    "y = df_train[\"Status\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model Evaluation (First Look)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation within the data preprocessing notebook indicates that the features **AnyHealthcare** and **MentHlth** do not exhibit a statistically significant correlation with the target variable **Status**. Consequently, these two features will be excluded from the dataset, and the model will be retrained to assess the impact of this refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────────┐\n",
      "│  Training the model (With All Features)  │\n",
      "└──────────────────────────────────────────┘\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.80      0.80     33403\n",
      "         1.0       0.80      0.79      0.79     33439\n",
      "\n",
      "    accuracy                           0.80     66842\n",
      "   macro avg       0.80      0.80      0.80     66842\n",
      "weighted avg       0.80      0.80      0.80     66842\n",
      "\n",
      "┌──────────────────────────────────────────────┐\n",
      "│  Training the model (With Reduced Features)  │\n",
      "└──────────────────────────────────────────────┘\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.80      0.80     33403\n",
      "         1.0       0.80      0.79      0.79     33439\n",
      "\n",
      "    accuracy                           0.79     66842\n",
      "   macro avg       0.79      0.79      0.79     66842\n",
      "weighted avg       0.79      0.79      0.79     66842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Traing the model (With All Features)\n",
    "styler.draw_box(\"Training the model (With All Features)\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Traing the model (With reduced Features)\n",
    "styler.draw_box(\"Training the model (With Reduced Features)\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Drop the specified columns from X_train and X_test\n",
    "X_train_reduced = X_train.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "X_test_reduced = X_test.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "\n",
    "model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_reduced)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics after Feature Selection**\n",
    "\n",
    "After applying feature selection, the evaluation metrics reveal a decline in model accuracy. This suggests that the removed features may have contained information critical to the model's performance.\n",
    "\n",
    "→ *Therefore, to ensure optimal performance, all features in the current dataset will be retained for further analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section delves deeper into feature selection by employing a **Wrapper Method** known as **Recursive Feature Elimination with Cross-Validation (REFCV)**. This technique iteratively evaluates the performance of a chosen machine learning model on progressively smaller subsets of features. Features deemed least impactful on the model's performance are eliminated in each step. The RECFCV process continues until the optimal feature combination is identified, resulting in the model achieving its highest accuracy.\n",
    "\n",
    "While sequential feature selection methods, such as forward selection or backward selection, might be considered for this task, they are often susceptible to instability and prone to overfitting. Due to these potential drawbacks, this approach is not employed in this instance. RECFCV, on the other hand, offers a more robust and reliable method for identifying the optimal feature subset that maximizes model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│  Feature Selection (Wrapper Method - Recursive Feature Elimination with Cross-Validation (RFECV))  │\n",
      "└────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "Selected features using Logistic Regression and RFECV: Index(['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',\n",
      "       'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
      "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
      "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income',\n",
      "       'ExtraMedTest', 'ExtraAlcoholTest'],\n",
      "      dtype='object')\n",
      "Size of selected features: 23\n"
     ]
    }
   ],
   "source": [
    "styler.draw_box(\"Feature Selection (Wrapper Method - Recursive Feature Elimination with Cross-Validation (RFECV))\")\n",
    "\n",
    "# Create Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Create RFECV with Logistic Regression model\n",
    "selector = RFECV(estimator=logistic_model, cv=5, scoring=\"accuracy\")\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "\n",
    "print(\"Selected features using Logistic Regression and RFECV:\", selected_features)\n",
    "print(\"Size of selected features:\", len(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model Evaluation (Second Look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────────────────────┐\n",
      "│  Training the model (Without Hyperparameter Tuning)  │\n",
      "└──────────────────────────────────────────────────────┘\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.80      0.80    133702\n",
      "         1.0       0.80      0.79      0.79    133666\n",
      "\n",
      "    accuracy                           0.79    267368\n",
      "   macro avg       0.79      0.79      0.79    267368\n",
      "weighted avg       0.79      0.79      0.79    267368\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.80      0.80     33403\n",
      "         1.0       0.80      0.79      0.79     33439\n",
      "\n",
      "    accuracy                           0.80     66842\n",
      "   macro avg       0.80      0.80      0.80     66842\n",
      "weighted avg       0.80      0.80      0.80     66842\n",
      "\n",
      "Accuracy on Training Data: 0.7948221178301068\n",
      "Accuracy on Testing Data: 0.7952036144938811\n",
      "\n",
      "The model is underfitting to the training data.\n"
     ]
    }
   ],
   "source": [
    "# Traing the model\n",
    "styler.draw_box(\"Training the model (Without Hyperparameter Tuning)\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "neko.evaluate_model(model, X_train[selected_features], y_train, X_test[selected_features], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature selection process yielded a noteworthy result: all features were retained for model training. This outcome suggests that each feature contributes meaningfully to the model's final performance. Consequently, the entire feature set will be utilized for training. This decision is further supported by the observed improvements in accuracy and F1-score, which are critical metrics for assessing model effectiveness.\n",
    "\n",
    "Furthermore, the close similarity between accuracy and F1-score on both the training and testing datasets indicates strong model generalizability. In simpler terms, the model performs well not only on the data it was trained on but also on unseen data, demonstrating its ability to learn underlying patterns and make accurate predictions on new information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model Tuning (Hyperparameter Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Warning suppression\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "    \"C\": np.logspace(-4, 4, 50),\n",
    "    \"solver\": [\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\", \"saga\"],\n",
    "    \"max_iter\": [100, 1000, 2500, 5000],\n",
    "    \"l1_ratio\": np.linspace(0, 1, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis, there is a strong likelihood of achieving an optimal or near-optimal solution by setting the number of iterations to `60`. To further improve the probability of success, I propose increasing the number of iterations (n_iter) to `100`. This adjustment will allow the model to explore a broader range of hyperparameters, potentially identifying an even more optimal solution.\n",
    "\n",
    "https://web.archive.org/web/20160701182750/http://blog.dato.com/how-to-evaluate-machine-learning-models-part-4-hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hyperparameter Tuning For Polynomial Degree: 1\n",
      "┌────────────────────────────────┐\n",
      "│  Best parameters for degree 1  │\n",
      "└────────────────────────────────┘\n",
      "{'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 5000, 'l1_ratio': 0.3333333333333333, 'C': 0.3906939937054613}\n",
      "\n",
      "Classification Report for degree 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.75      0.75     33416\n",
      "         1.0       0.74      0.74      0.74     33196\n",
      "\n",
      "    accuracy                           0.75     66612\n",
      "   macro avg       0.75      0.75      0.75     66612\n",
      "weighted avg       0.75      0.75      0.75     66612\n",
      "\n",
      ">>> Hyperparameter Tuning For Polynomial Degree: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 25\u001b[0m\n\u001b[0;32m     16\u001b[0m logistic_regression \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     17\u001b[0m randon_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     18\u001b[0m     logistic_regression,\n\u001b[0;32m     19\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m \u001b[43mrandon_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_poly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Store the best model and its parameters\u001b[39;00m\n\u001b[0;32m     28\u001b[0m best_models[degree] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: randon_search\u001b[38;5;241m.\u001b[39mbest_estimator_,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m\"\u001b[39m: randon_search\u001b[38;5;241m.\u001b[39mbest_params_,\n\u001b[0;32m     31\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\huuqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Polynomial degrees\n",
    "degrees = range(1, 3)  # 1 to 2 (because of computational cost for higher degrees)\n",
    "\n",
    "# Store best models\n",
    "best_models = {}\n",
    "\n",
    "# Loop through each degree\n",
    "for degree in degrees:\n",
    "    print(\">>> Hyperparameter Tuning For Polynomial Degree:\", degree)\n",
    "\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly_features.fit_transform(X_train[selected_features])\n",
    "    X_test_poly = poly_features.transform(X_test[selected_features])\n",
    "\n",
    "    # Grid search\n",
    "    logistic_regression = LogisticRegression(random_state=42)\n",
    "    randon_search = RandomizedSearchCV(\n",
    "        logistic_regression,\n",
    "        param_distributions=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"f1_weighted\",\n",
    "        n_jobs=6,\n",
    "        n_iter=100,\n",
    "    )\n",
    "    randon_search.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Store the best model and its parameters\n",
    "    best_models[degree] = {\n",
    "        \"best_model\": randon_search.best_estimator_,\n",
    "        \"best_params\": randon_search.best_params_,\n",
    "    }\n",
    "\n",
    "    styler.draw_box(f\"Best parameters for degree {degree}\")\n",
    "    print(randon_search.best_params_)\n",
    "\n",
    "    # Evaluate model with best parameters\n",
    "    best_logistic = randon_search.best_estimator_\n",
    "\n",
    "    # Show classification report\n",
    "    y_pred = best_logistic.predict(X_test_poly)\n",
    "\n",
    "    print(f\"\\nClassification Report for degree {degree}:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
