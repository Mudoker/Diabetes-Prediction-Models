{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "### COSC2753 - Machine Learning\n",
    "\n",
    "# **Logistic Regression**\n",
    "\n",
    "<center>────────────────────────────</center>\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────┐\n",
      "│  Checking Package Versions...  │\n",
      "└────────────────────────────────┘\n",
      ">>> numpy is up to date: 1.26.4\n",
      ">>> pandas is up to date: 2.2.1\n",
      ">>> seaborn is up to date: 0.13.2\n",
      ">>> matplotlib is up to date: 3.8.3\n",
      ">>> tabulate is up to date: 0.9.0\n",
      ">>> sklearn is up to date: 1.4.1.post1\n",
      ">>> statsmodels is up to date: 0.14.1\n",
      ">>> imblearn is up to date: 0.12.2\n",
      "\u001b[1m\u001b[3m\n",
      "Done checking packages version...\n",
      "\u001b[0m\n",
      "┌───────────────────────────┐\n",
      "│  Initializing Project...  │\n",
      "└───────────────────────────┘\n",
      "\n",
      "    /\\_____/\\\n",
      "   /  x   o  \\\n",
      "  ( ==  ^  == )       Neko has arrived!\n",
      "   )         (        An data visualizing extension for analyzing DataFrames.\n",
      "  (           )       Art: https://www.asciiart.eu/animals/cats.\n",
      " ( (  )   (  ) )\n",
      "(__(__)___(__)__)\n",
      "\n",
      "\u001b[1m\u001b[3mDone initializing project...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "import warnings\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Reload modules\n",
    "sys.path.append(\"../../\")  # Root directory\n",
    "modules_to_reload = [\n",
    "    \"scripts.styler\",\n",
    "    \"scripts.neko\",\n",
    "    \"scripts.utils\",\n",
    "    \"scripts.outlier_detector\",\n",
    "]\n",
    "\n",
    "# Reload modules if they have been modified\n",
    "missing_modules = []\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    else:\n",
    "        missing_modules.append(module_name)\n",
    "\n",
    "# Recache missing modules\n",
    "if missing_modules:\n",
    "    print(f\"Modules {missing_modules} not found. \\nRecaching...\")\n",
    "\n",
    "# Import user-defined scripts\n",
    "from scripts.styler import Styler\n",
    "from scripts.neko import Neko\n",
    "from scripts.utils import Utils\n",
    "from scripts.outlier_detector import OutlierDetector\n",
    "\n",
    "# Initialize styler\n",
    "styler = Styler()  # Text Styler\n",
    "\n",
    "# Check package versions\n",
    "styler.draw_box(\"Checking Package Versions...\")\n",
    "\n",
    "try:\n",
    "    with open(\"../../requirements.txt\", \"r\") as file:\n",
    "        requirements = file.readlines()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '../../requirements.txt' not found.\")\n",
    "\n",
    "packages_to_check = [np, pd, sns, matplotlib, tabulate, sklearn, statsmodels, imblearn]\n",
    "\n",
    "for package in packages_to_check:\n",
    "    Utils.version_check(package, requirements=requirements)\n",
    "\n",
    "styled_text = styler.style(\n",
    "    \"\\nDone checking packages version...\\n\", bold=True, italic=True\n",
    ")\n",
    "print(styled_text)\n",
    "\n",
    "# Initialize objects\n",
    "styler.draw_box(\"Initializing Project...\")\n",
    "neko = Neko()  # Panda extension\n",
    "bullet = \">>>\"  # Bullet point\n",
    "plt = matplotlib.pyplot  # Matplotlib\n",
    "\n",
    "# Configuration\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "styled_text = styler.style(\"Done initializing project...\", bold=True, italic=True)\n",
    "print(styled_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "metadata": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────┐\n",
      "│  Data Loaded Successfully  │\n",
      "└────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load data\n",
    "    df_train = pd.read_csv(\"../../data/processed/data_train_processed.csv\")\n",
    "    df_test = pd.read_csv(\"../../data/test/data_test.csv\")\n",
    "\n",
    "    styler.draw_box(\"Data Loaded Successfully\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71262 entries, 0 to 71261\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   HighBP                71262 non-null  int64  \n",
      " 1   HighChol              71262 non-null  int64  \n",
      " 2   CholCheck             71262 non-null  int64  \n",
      " 3   BMI                   71262 non-null  int64  \n",
      " 4   Smoker                71262 non-null  int64  \n",
      " 5   Stroke                71262 non-null  int64  \n",
      " 6   HeartDiseaseorAttack  71262 non-null  int64  \n",
      " 7   PhysActivity          71262 non-null  int64  \n",
      " 8   Fruits                71262 non-null  int64  \n",
      " 9   Veggies               71262 non-null  int64  \n",
      " 10  HvyAlcoholConsump     71262 non-null  int64  \n",
      " 11  AnyHealthcare         71262 non-null  int64  \n",
      " 12  NoDocbcCost           71262 non-null  int64  \n",
      " 13  GenHlth               71262 non-null  int64  \n",
      " 14  MentHlth              71262 non-null  int64  \n",
      " 15  PhysHlth              71262 non-null  int64  \n",
      " 16  DiffWalk              71262 non-null  int64  \n",
      " 17  Sex                   71262 non-null  int64  \n",
      " 18  Age                   71262 non-null  int64  \n",
      " 19  Education             71262 non-null  int64  \n",
      " 20  Income                71262 non-null  int64  \n",
      " 21  ExtraMedTest          71262 non-null  float64\n",
      " 22  ExtraAlcoholTest      71262 non-null  float64\n",
      " 23  Status                71262 non-null  int64  \n",
      "dtypes: float64(2), int64(22)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>ExtraMedTest</th>\n",
       "      <th>ExtraAlcoholTest</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.416</td>\n",
       "      <td>-7.566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0       0         0          1   22       0       0                     0   \n",
       "1       0         0          1   21       0       0                     0   \n",
       "2       0         0          1   22       0       0                     0   \n",
       "3       0         0          1   21       0       0                     0   \n",
       "4       0         0          1   22       1       0                     0   \n",
       "5       1         0          1   29       0       0                     0   \n",
       "6       0         0          1   21       0       0                     0   \n",
       "7       0         0          1   22       0       0                     0   \n",
       "8       1         0          1   31       0       0                     0   \n",
       "9       0         0          1   20       0       0                     0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  \\\n",
       "0             1       1        1                  0              1   \n",
       "1             1       1        1                  0              1   \n",
       "2             1       1        1                  0              1   \n",
       "3             1       1        1                  0              1   \n",
       "4             1       1        1                  0              1   \n",
       "5             1       1        1                  0              1   \n",
       "6             1       1        1                  0              1   \n",
       "7             1       1        1                  0              1   \n",
       "8             1       1        1                  0              1   \n",
       "9             1       1        1                  0              1   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  \\\n",
       "0            0        1         0         0         0    0    6          6   \n",
       "1            0        1         0         0         0    0    6          6   \n",
       "2            0        1         0         0         0    0    6          6   \n",
       "3            0        1         0         0         0    0    6          6   \n",
       "4            0        1         0         0         0    0    6          6   \n",
       "5            0        2         0         0         0    1    9          6   \n",
       "6            0        1         0         0         0    0    3          6   \n",
       "7            0        1         0         0         0    0    7          6   \n",
       "8            0        2         0         0         0    1   11          6   \n",
       "9            0        1         0         0         0    0    6          6   \n",
       "\n",
       "   Income  ExtraMedTest  ExtraAlcoholTest  Status  \n",
       "0       8        -7.416            -7.566       0  \n",
       "1       8        -7.416            -7.566       0  \n",
       "2       8        -7.416            -7.566       0  \n",
       "3       8        -7.416            -7.566       0  \n",
       "4       8        -7.416            -7.566       0  \n",
       "5       8        -7.416            -7.566       0  \n",
       "6       8        -7.416            -7.566       0  \n",
       "7       8        -7.416            -7.566       0  \n",
       "8       8        -7.416            -7.566       0  \n",
       "9       8        -7.416            -7.566       0  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Techniques for Logistic Regression Models\n",
    "\n",
    "Logistic regression models often benefit from scaled features to enhance accuracy. When dealing with varied range numerical data, two common scaling techniques are **standardization** (using a *StandardScaler*) and **Normalisation** (using a *MinMaxScaler*).\n",
    "\n",
    "**Limitations of Log Transformation and StandardScaler:** \n",
    "The *StandardScaler*, which typically involves log transformation followed by standardization, might not be suitable for this specific case. This method can encounter issues when the data contains zeros or negative values, potentially leading to inaccurate transformations.\n",
    "\n",
    "Therefore, the *MinMaxScaler* is a more appropriate choice for this scenario. This technique effectively handles skewed data by rescaling each feature to a specific range (often 0 to 1). This ensures that all features contribute equally to the logistic regression model, improving its ability to learn the underlying relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>ExtraMedTest</th>\n",
       "      <th>ExtraAlcoholTest</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.000</td>\n",
       "      <td>71262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.522</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.224</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.795</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          HighBP   HighChol  CholCheck        BMI     Smoker     Stroke  \\\n",
       "count  71262.000  71262.000  71262.000  71262.000  71262.000  71262.000   \n",
       "mean       0.522      0.503      0.974      0.190      0.452      0.050   \n",
       "std        0.500      0.500      0.160      0.074      0.498      0.218   \n",
       "min        0.000      0.000      0.000      0.000      0.000      0.000   \n",
       "25%        0.000      0.000      1.000      0.141      0.000      0.000   \n",
       "50%        1.000      1.000      1.000      0.176      0.000      0.000   \n",
       "75%        1.000      1.000      1.000      0.224      1.000      0.000   \n",
       "max        1.000      1.000      1.000      1.000      1.000      1.000   \n",
       "\n",
       "       HeartDiseaseorAttack  PhysActivity     Fruits    Veggies  \\\n",
       "count             71262.000     71262.000  71262.000  71262.000   \n",
       "mean                  0.125         0.745      0.636      0.809   \n",
       "std                   0.330         0.436      0.481      0.393   \n",
       "min                   0.000         0.000      0.000      0.000   \n",
       "25%                   0.000         0.000      0.000      1.000   \n",
       "50%                   0.000         1.000      1.000      1.000   \n",
       "75%                   0.000         1.000      1.000      1.000   \n",
       "max                   1.000         1.000      1.000      1.000   \n",
       "\n",
       "       HvyAlcoholConsump  AnyHealthcare  NoDocbcCost    GenHlth   MentHlth  \\\n",
       "count          71262.000      71262.000    71262.000  71262.000  71262.000   \n",
       "mean               0.044          0.964        0.070      0.402      0.076   \n",
       "std                0.206          0.186        0.255      0.270      0.219   \n",
       "min                0.000          0.000        0.000      0.000      0.000   \n",
       "25%                0.000          1.000        0.000      0.250      0.000   \n",
       "50%                0.000          1.000        0.000      0.500      0.000   \n",
       "75%                0.000          1.000        0.000      0.500      0.000   \n",
       "max                1.000          1.000        1.000      1.000      1.000   \n",
       "\n",
       "        PhysHlth   DiffWalk        Sex        Age  Education     Income  \\\n",
       "count  71262.000  71262.000  71262.000  71262.000  71262.000  71262.000   \n",
       "mean       0.129      0.192      0.471      0.645      0.805      0.723   \n",
       "std        0.288      0.394      0.499      0.221      0.198      0.290   \n",
       "min        0.000      0.000      0.000      0.000      0.000      0.000   \n",
       "25%        0.000      0.000      0.000      0.500      0.600      0.571   \n",
       "50%        0.000      0.000      0.000      0.667      0.800      0.857   \n",
       "75%        0.067      0.000      1.000      0.833      1.000      1.000   \n",
       "max        1.000      1.000      1.000      1.000      1.000      1.000   \n",
       "\n",
       "       ExtraMedTest  ExtraAlcoholTest   Status  \n",
       "count     71262.000         71262.000  71262.0  \n",
       "mean          0.594             0.589      0.5  \n",
       "std           0.247             0.250      0.5  \n",
       "min           0.000             0.000      0.0  \n",
       "25%           0.463             0.462      0.0  \n",
       "50%           0.500             0.500      0.5  \n",
       "75%           0.805             0.795      1.0  \n",
       "max           1.000             1.000      1.0  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale features using min-max scaler (Normalization)\n",
    "df_train = neko.scale_feature(df_train, \"norm\")\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df_train.drop(columns=[\"Status\"], axis=1)\n",
    "y = df_train[\"Status\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model Evaluation (First Look)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation within the data preprocessing notebook indicates that the features **AnyHealthcare** and **MentHlth** do not exhibit a statistically significant correlation with the target variable **Status**. Consequently, these two features will be excluded from the dataset, and the model will be retrained to assess the impact of this refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────────┐\n",
      "│  Training the model (With All Features)  │\n",
      "└──────────────────────────────────────────┘\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81      7158\n",
      "         1.0       0.83      0.76      0.79      7095\n",
      "\n",
      "    accuracy                           0.80     14253\n",
      "   macro avg       0.81      0.80      0.80     14253\n",
      "weighted avg       0.81      0.80      0.80     14253\n",
      "\n",
      "┌──────────────────────────────────────────────┐\n",
      "│  Training the model (With Reduced Features)  │\n",
      "└──────────────────────────────────────────────┘\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.83      0.80      7158\n",
      "         1.0       0.82      0.76      0.79      7095\n",
      "\n",
      "    accuracy                           0.80     14253\n",
      "   macro avg       0.80      0.80      0.80     14253\n",
      "weighted avg       0.80      0.80      0.80     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Traing the model (With All Features)\n",
    "styler.draw_box(\"Training the model (With All Features)\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Traing the model (With reduced Features)\n",
    "styler.draw_box(\"Training the model (With Reduced Features)\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Drop the specified columns from X_train and X_test\n",
    "X_train_reduced = X_train.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "X_test_reduced = X_test.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "\n",
    "model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_reduced)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics after Feature Selection**\n",
    "\n",
    "After applying feature selection, the evaluation metrics reveal a decline in model accuracy. This suggests that the removed features may have contained information critical to the model's performance.\n",
    "\n",
    "→ *Therefore, to ensure optimal performance, all features in the current dataset will be retained for further analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section delves deeper into feature selection by employing a **Wrapper Method** known as **Recursive Feature Elimination with Cross-Validation (REFCV)**. This technique iteratively evaluates the performance of a chosen machine learning model on progressively smaller subsets of features. Features deemed least impactful on the model's performance are eliminated in each step. The RECFCV process continues until the optimal feature combination is identified, resulting in the model achieving its highest accuracy.\n",
    "\n",
    "While sequential feature selection methods, such as forward selection or backward selection, might be considered for this task, they are often susceptible to instability and prone to overfitting. Due to these potential drawbacks, this approach is not employed in this instance. RECFCV, on the other hand, offers a more robust and reliable method for identifying the optimal feature subset that maximizes model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│  Feature Selection (Wrapper Method - Recursive Feature Elimination with Cross-Validation (RFECV))  │\n",
      "└────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "Selected features using Logistic Regression and RFECV: Index(['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Stroke',\n",
      "       'HeartDiseaseorAttack', 'HvyAlcoholConsump', 'NoDocbcCost', 'GenHlth',\n",
      "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income',\n",
      "       'ExtraMedTest', 'ExtraAlcoholTest'],\n",
      "      dtype='object')\n",
      "Size of selected features: 18\n"
     ]
    }
   ],
   "source": [
    "styler.draw_box(\"Feature Selection (Wrapper Method - Recursive Feature Elimination with Cross-Validation (RFECV))\")\n",
    "\n",
    "# Create Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Create RFECV with Logistic Regression model\n",
    "selector = RFECV(estimator=logistic_model, cv=5, scoring=\"accuracy\")\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "\n",
    "print(\"Selected features using Logistic Regression and RFECV:\", selected_features)\n",
    "print(\"Size of selected features:\", len(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model Evaluation (Second Look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────────────────────┐\n",
      "│  Training the model (Without Hyperparameter Tuning)  │\n",
      "└──────────────────────────────────────────────────────┘\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.84      0.81     28473\n",
      "         1.0       0.83      0.77      0.80     28536\n",
      "\n",
      "    accuracy                           0.81     57009\n",
      "   macro avg       0.81      0.81      0.81     57009\n",
      "weighted avg       0.81      0.81      0.81     57009\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81      7158\n",
      "         1.0       0.83      0.76      0.79      7095\n",
      "\n",
      "    accuracy                           0.80     14253\n",
      "   macro avg       0.80      0.80      0.80     14253\n",
      "weighted avg       0.80      0.80      0.80     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Traing the model\n",
    "styler.draw_box(\"Training the model (Without Hyperparameter Tuning)\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "neko.evaluate_model(\n",
    "    model, X_train[selected_features], y_train, X_test[selected_features], y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **feature selection process** identified a significant result. Only **18 features** were ultimately chosen for the prediction model. This reduced feature set will be used for training due to the observed increase in accuracy, rising from **80% to 81%**. This decision is further bolstered by improvements in both **accuracy** and **F1-score**, which are crucial metrics for evaluating model performance.\n",
    "\n",
    "Furthermore, the high degree of similarity between **accuracy** and **F1-score** on both the training and testing datasets suggests **strong model generalizability**. In simpler terms, the model performs well not only on the data it was trained on but also on unseen data. This signifies the model's ability to learn underlying patterns and make accurate predictions on new information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Outlier Detection and Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers for MentHlth:\n",
      "╭─────────────────┬─────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Key             │ Value                                                                       │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Unique Outliers │ 0.23333333333333334, 1.0, 0.3333333333333333, 0.2, 0.26666666666666666, ... │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Lower Bound     │ 0.0                                                                         │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Upper Bound     │ 0.0                                                                         │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Threshold       │ 1.5                                                                         │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Total Outliers  │ 16284                                                                       │\n",
      "╰─────────────────┴─────────────────────────────────────────────────────────────────────────────╯\n",
      ">>> Resolving outliers...\n",
      "\n",
      "╭─────────────────┬─────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Key             │ Value                                                                       │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Unique Outliers │ 0.23333333333333334, 1.0, 0.3333333333333333, 0.2, 0.26666666666666666, ... │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Lower Bound     │ 0.0                                                                         │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Upper Bound     │ 0.0                                                                         │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Threshold       │ 1.5                                                                         │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Total Outliers  │ 16284                                                                       │\n",
      "╰─────────────────┴─────────────────────────────────────────────────────────────────────────────╯\n",
      ">>> Resolving outliers...\n",
      ">>> Outliers for MentHlth resolved.\n",
      "\n",
      "Outliers for PhysHlth:\n",
      "╭─────────────────┬────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Key             │ Value                                                                      │\n",
      "├─────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Unique Outliers │ 0.5, 1.0, 0.9666666666666667, 0.3333333333333333, 0.23333333333333334, ... │\n",
      "├─────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Lower Bound     │ -0.1                                                                       │\n",
      "├─────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Upper Bound     │ 0.16666666666666669                                                        │\n",
      "├─────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Threshold       │ 1.5                                                                        │\n",
      "├─────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Total Outliers  │ 11417                                                                      │\n",
      "╰─────────────────┴────────────────────────────────────────────────────────────────────────────╯\n",
      ">>> Resolving outliers...\n",
      ">>> Outliers for PhysHlth resolved.\n",
      "\n",
      "Outliers for BMI:\n",
      "╭─────────────────┬─────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Key             │ Value                                                                                   │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Unique Outliers │ 0.3529411764705882, 0.388235294117647, 0.3647058823529411, 0.3764705882352941, 0.4, ... │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Lower Bound     │ 0.017647058823529432                                                                    │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Upper Bound     │ 0.34705882352941175                                                                     │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Threshold       │ 1.5                                                                                     │\n",
      "├─────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Total Outliers  │ 2521                                                                                    │\n",
      "╰─────────────────┴─────────────────────────────────────────────────────────────────────────────────────────╯\n",
      ">>> Resolving outliers...\n",
      ">>> Outliers for BMI resolved.\n",
      "\n",
      "Outliers for ExtraMedTest:\n",
      "╭─────────────────┬──────────────────────╮\n",
      "│ Key             │ Value                │\n",
      "├─────────────────┼──────────────────────┤\n",
      "│ Unique Outliers │ None                 │\n",
      "├─────────────────┼──────────────────────┤\n",
      "│ Lower Bound     │ -0.05020547658038038 │\n",
      "├─────────────────┼──────────────────────┤\n",
      "│ Upper Bound     │ 1.3181232859482281   │\n",
      "├─────────────────┼──────────────────────┤\n",
      "│ Threshold       │ 1.5                  │\n",
      "├─────────────────┼──────────────────────┤\n",
      "│ Total Outliers  │ 0                    │\n",
      "╰─────────────────┴──────────────────────╯\n",
      ">>> Resolving outliers...\n",
      ">>> Outliers for ExtraMedTest resolved.\n",
      "\n",
      "Outliers for ExtraAlcoholTest:\n",
      "╭─────────────────┬────────────────────╮\n",
      "│ Key             │ Value              │\n",
      "├─────────────────┼────────────────────┤\n",
      "│ Unique Outliers │ None               │\n",
      "├─────────────────┼────────────────────┤\n",
      "│ Lower Bound     │ -0.037075334425065 │\n",
      "├─────────────────┼────────────────────┤\n",
      "│ Upper Bound     │ 1.294245200655039  │\n",
      "├─────────────────┼────────────────────┤\n",
      "│ Threshold       │ 1.5                │\n",
      "├─────────────────┼────────────────────┤\n",
      "│ Total Outliers  │ 0                  │\n",
      "╰─────────────────┴────────────────────╯\n",
      ">>> Resolving outliers...\n",
      ">>> Outliers for ExtraAlcoholTest resolved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize outlier detector\n",
    "outlier_detector = OutlierDetector()\n",
    "\n",
    "# Specify non-binary numerical columns\n",
    "numerical_columns = [\"MentHlth\", \"PhysHlth\", \"BMI\", \"ExtraMedTest\", \"ExtraAlcoholTest\"]\n",
    "\n",
    "# Create a copy of the DataFrame (for comparison purposes)\n",
    "df_tmp = df_train.copy()\n",
    "\n",
    "# Detect and handle outliers\n",
    "for column in numerical_columns:\n",
    "    # Detect outliers using IQR method\n",
    "    outliers = outlier_detector.find_outliers_iqr(df_train[column], threshold=1.5)\n",
    "\n",
    "    # Show outliers results\n",
    "    print(f\"Outliers for {column}:\")\n",
    "    print(outliers[\"table\"])\n",
    "\n",
    "    # Handle outliers (Winsorization)\n",
    "    print(\">>> Resolving outliers...\")\n",
    "    if outliers[\"total_outliers\"] > 0:\n",
    "        # Get the lower and upper bounds\n",
    "        lower_bound = outliers[\"lower_bound\"]\n",
    "        upper_bound = outliers[\"upper_bound\"]\n",
    "\n",
    "        # Winsorize the outliers\n",
    "        df_tmp[column] = np.clip(df_train[column], lower_bound, upper_bound)\n",
    "\n",
    "    print(f\">>> Outliers for {column} resolved.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Model Evaluation (Third Look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────┐\n",
      "│  Training the model  │\n",
      "└──────────────────────┘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.83      0.80     28473\n",
      "         1.0       0.82      0.77      0.79     28536\n",
      "\n",
      "    accuracy                           0.80     57009\n",
      "   macro avg       0.80      0.80      0.80     57009\n",
      "weighted avg       0.80      0.80      0.80     57009\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.83      0.80      7158\n",
      "         1.0       0.82      0.76      0.79      7095\n",
      "\n",
      "    accuracy                           0.80     14253\n",
      "   macro avg       0.80      0.80      0.80     14253\n",
      "weighted avg       0.80      0.80      0.80     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_tmp = df_tmp.drop(columns=[\"Status\"], axis=1)\n",
    "y_tmp = df_tmp[\"Status\"]\n",
    "\n",
    "X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Traing the model\n",
    "styler.draw_box(\"Training the model\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_tmp, y_train_tmp)\n",
    "\n",
    "neko.evaluate_model(model, X_train_tmp, y_train_tmp, X_test_tmp, y_test_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **removal of outliers** from the data resulted in a **1% decrease** in model accuracy. This suggests that the outliers may have contained relevant information that contributed to the model's performance. Consequently, the model will be **retrained using the complete original dataset** to achieve optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model Tuning (Hyperparameter Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Warning suppression\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "    \"C\": np.logspace(-3, 3, 20),\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "    \"max_iter\": [1000, 2500, 5000],\n",
    "    \"l1_ratio\": np.linspace(0, 1, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis, there is a strong likelihood of achieving an optimal or near-optimal solution by setting the number of iterations to `60`. To further improve the probability of success, I propose increasing the number of iterations (n_iter) to `100`. This adjustment will allow the model to explore a broader range of hyperparameters, potentially identifying an even more optimal solution.\n",
    "\n",
    "https://web.archive.org/web/20160701182750/http://blog.dato.com/how-to-evaluate-machine-learning-models-part-4-hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hyperparameter Tuning For Polynomial Degree: 1\n",
      "┌────────────────────────────────┐\n",
      "│  Best parameters for degree 1  │\n",
      "└────────────────────────────────┘\n",
      "{'C': 2.976351441631316, 'l1_ratio': 0.5555555555555556, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best accuracy: 0.8071532450861929\n",
      ">>> Hyperparameter Tuning For Polynomial Degree: 2\n",
      "┌────────────────────────────────┐\n",
      "│  Best parameters for degree 2  │\n",
      "└────────────────────────────────┘\n",
      "{'C': 1.438449888287663, 'l1_ratio': 0.7777777777777777, 'max_iter': 5000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best accuracy: 0.8289773622459047\n"
     ]
    }
   ],
   "source": [
    "# Polynomial degrees\n",
    "degrees = range(1, 3)  # 1 to 2 (because of computational cost for higher degrees)\n",
    "\n",
    "# Store best models\n",
    "best_models = {}\n",
    "\n",
    "# Loop through each degree\n",
    "for degree in degrees:\n",
    "    print(\">>> Hyperparameter Tuning For Polynomial Degree:\", degree)\n",
    "\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly_features.fit_transform(X_train[selected_features])\n",
    "    X_test_poly = poly_features.transform(X_test[selected_features])\n",
    "\n",
    "    # Grid search\n",
    "    logistic_regression = LogisticRegression(random_state=42)\n",
    "\n",
    "    search = HalvingGridSearchCV(\n",
    "        logistic_regression,\n",
    "        param_grid=param_grid,\n",
    "        cv=10,\n",
    "        scoring=\"f1_weighted\",\n",
    "        n_jobs=2,\n",
    "    )\n",
    "    search.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Store the best model and its parameters\n",
    "    best_models[degree] = {\n",
    "        \"best_model\": search.best_estimator_,\n",
    "        \"best_params\": search.best_params_,\n",
    "    }\n",
    "\n",
    "    styler.draw_box(f\"Best parameters for degree {degree}\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    print(\"Best accuracy:\", search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
