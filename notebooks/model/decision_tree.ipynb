{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "### COSC2753 - Machine Learning\n",
    "\n",
    "# **Decision Tree**\n",
    "\n",
    "<center>────────────────────────────</center>\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────┐\n",
      "│  Validating Package Versions...  │\n",
      "└──────────────────────────────────┘\n",
      ">>> numpy is up to date: 1.26.4\n",
      ">>> pandas is up to date: 2.2.1\n",
      ">>> tabulate is up to date: 0.9.0\n",
      ">>> sklearn is up to date: 1.4.1.post1\n",
      ">>> statsmodels is up to date: 0.14.1\n",
      ">>> imblearn is up to date: 0.12.2\n",
      "\u001b[1m\u001b[3m\n",
      "Done validating packages\n",
      "\u001b[0m\n",
      "┌───────────────────────────┐\n",
      "│  Initializing Project...  │\n",
      "└───────────────────────────┘\n",
      "\n",
      "    /\\_____/\\\n",
      "   /  x   o  \\\n",
      "  ( ==  ^  == )       Neko has arrived!\n",
      "   )         (        An data visualizing extension for analyzing DataFrames.\n",
      "  (           )       Art: https://www.asciiart.eu/animals/cats.\n",
      " ( (  )   (  ) )\n",
      "(__(__)___(__)__)\n",
      "\n",
      "\u001b[1m\u001b[3mDone initializing project...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "import warnings\n",
    "\n",
    "# Reload modules\n",
    "sys.path.append(\"../../\")  # Root directory\n",
    "modules_to_reload = [\n",
    "    \"scripts.styler\",\n",
    "    \"scripts.neko\",\n",
    "    \"scripts.utils\",\n",
    "]\n",
    "\n",
    "# Reload modules if they have been modified\n",
    "missing_modules = []\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    else:\n",
    "        missing_modules.append(module_name)\n",
    "\n",
    "# Recache missing modules\n",
    "if missing_modules:\n",
    "    print(f\"Modules {missing_modules} not found. \\nRecaching...\")\n",
    "\n",
    "# Import user-defined scripts\n",
    "from scripts.styler import Styler\n",
    "from scripts.neko import Neko\n",
    "from scripts.utils import Utils\n",
    "\n",
    "# Initialize styler\n",
    "styler = Styler()  # Text Styler\n",
    "\n",
    "# Check package versions\n",
    "styler.draw_box(\"Validating Package Versions...\")\n",
    "\n",
    "try:\n",
    "    with open(\"../../requirements.txt\", \"r\") as file:\n",
    "        requirements = file.readlines()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '../../requirements.txt' not found. Please check your directory!\")\n",
    "\n",
    "packages_to_check = [np, pd, tabulate, sklearn, statsmodels, imblearn]\n",
    "\n",
    "for package in packages_to_check:\n",
    "    Utils.version_check(package, requirements=requirements)\n",
    "\n",
    "styled_text = styler.style(\"\\nDone validating packages\\n\", bold=True, italic=True)\n",
    "print(styled_text)\n",
    "\n",
    "# Initialize objects\n",
    "styler.draw_box(\"Initializing Project...\")\n",
    "neko = Neko()  # Panda extension\n",
    "bullet = \">>>\"  # Bullet point\n",
    "\n",
    "# Configuration\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "styled_text = styler.style(\"Done initializing project...\", bold=True, italic=True)\n",
    "print(styled_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────┐\n",
      "│  Data Loaded Successfully  │\n",
      "└────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load data\n",
    "    df_train = pd.read_csv(\"../../data/processed/data_train_processed.csv\")\n",
    "\n",
    "    styler.draw_box(\"Data Loaded Successfully\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree-based methods offer a significant advantage over techniques like Logistic Regression in their inherent insensitivity to the scaling of input features. Unlike other models, tree-based algorithms can be directly applied to the data without requiring preprocessing to standardize the scale of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df_train.drop(columns=[\"Status\"], axis=1)\n",
    "y = df_train[\"Status\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Model Evaluation (First Attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28473\n",
      "           1       1.00      1.00      1.00     28536\n",
      "\n",
      "    accuracy                           1.00     57009\n",
      "   macro avg       1.00      1.00      1.00     57009\n",
      "weighted avg       1.00      1.00      1.00     57009\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      7158\n",
      "           1       0.81      0.83      0.82      7095\n",
      "\n",
      "    accuracy                           0.82     14253\n",
      "   macro avg       0.82      0.82      0.82     14253\n",
      "weighted avg       0.82      0.82      0.82     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "neko.evaluate_model(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous analysis, the filtering method identified features **'MentHlth'** and **'AnyHealthcare'** as insignificant for predicting the target variable. Consequently, these features will be excluded from the dataset to improve model performance and focus on the most impactful factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────────────┐\n",
      "│  Training the model (With Reduced Features)  │\n",
      "└──────────────────────────────────────────────┘\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28473\n",
      "           1       1.00      1.00      1.00     28536\n",
      "\n",
      "    accuracy                           1.00     57009\n",
      "   macro avg       1.00      1.00      1.00     57009\n",
      "weighted avg       1.00      1.00      1.00     57009\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      7158\n",
      "           1       0.81      0.81      0.81      7095\n",
      "\n",
      "    accuracy                           0.81     14253\n",
      "   macro avg       0.81      0.81      0.81     14253\n",
      "weighted avg       0.81      0.81      0.81     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Traing the model (With reduced Features)\n",
    "styler.draw_box(\"Training the model (With Reduced Features)\")\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Drop the specified columns from X_train and X_test\n",
    "X_train_reduced = X_train.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "X_test_reduced = X_test.drop(columns=[\"AnyHealthcare\", \"MentHlth\"])\n",
    "\n",
    "model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions\n",
    "neko.evaluate_model(model, X_train_reduced, y_train, X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Model Performance**\n",
    "\n",
    "The initial model achieved an accuracy of 82% without hyperparameter adjustments. This result demonstrates a promising foundation for further development. However, to optimize the model's effectiveness, additional techniques will be investigated.\n",
    "\n",
    "**Feature Selection Analysis**\n",
    "\n",
    "An initial exploration of feature selection was conducted by removing the features `MentHlth` and `AnyHealthcare` from the dataset. Unfortunately, this did not lead to any improvement in the model's performance. In fact, the accuracy even decreased slightly to 81%. Consequently, these features will be retained in the dataset for further analysis.\n",
    "\n",
    "**Addressing Overfitting**\n",
    "\n",
    "The model currently exhibits overfitting, with a training accuracy of `100%` and a validation accuracy of `81%`. To address this, hyperparameter tuning will be employed to optimize performance. This includes adjusting parameters like **ccp_values** for post-pruning and **min_samples_leaf** for pre-pruning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Warning Suppression\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],  # Splitting criterion\n",
    "    \"max_depth\": np.arange(3, 40, 2).tolist(),  # Maximum depth of the tree\n",
    "    \"min_samples_split\": np.arange(\n",
    "        2, 20, 2\n",
    "    ).tolist(),  # Minimum number of samples required to split an internal node\n",
    "    \"min_samples_leaf\": np.arange(\n",
    "        1, 20, 1\n",
    "    ).tolist(),  # Minimum number of samples required to be at a leaf node\n",
    "    \"max_features\": [\n",
    "        None,\n",
    "        \"sqrt\",\n",
    "        \"log2\",\n",
    "    ],  # Number of features to consider when looking for the best split\n",
    "    \"ccp_alpha\": np.arange(\n",
    "        0.0, 0.1, 0.01\n",
    "    ),  # Complexity parameter used for Minimal Cost-Complexity Pruning\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'ccp_alpha': 0.0, 'criterion': 'gini', 'max_depth': 13, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 18}\n",
      "Best accuracy: 0.8545458622595306\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "search = HalvingGridSearchCV(\n",
    "    estimator=classifier,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=2,\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", search.best_params_)\n",
    "print(\"Best accuracy:\", search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model Evaluation (Final Attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────┐\n",
      "│  Evaluation of the best model  │\n",
      "└────────────────────────────────┘\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88     28473\n",
      "           1       0.91      0.85      0.88     28536\n",
      "\n",
      "    accuracy                           0.88     57009\n",
      "   macro avg       0.88      0.88      0.88     57009\n",
      "weighted avg       0.88      0.88      0.88     57009\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      7158\n",
      "           1       0.88      0.82      0.85      7095\n",
      "\n",
      "    accuracy                           0.86     14253\n",
      "   macro avg       0.86      0.85      0.85     14253\n",
      "weighted avg       0.86      0.86      0.85     14253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "styler.draw_box(\"Evaluation of the best model\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "neko.evaluate_model(best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "The final model achieved an accuracy of `86%` on the validation set. This represents a significant improvement compared to the initial model's performance. Additionally, the model demonstrates good generalizability, with an accuracy of `88%` on the training set and `86%` on the validation set. This consistency suggests that the model is not overfitting the training data and can be effectively applied to new, unseen data.\n",
    "\n",
    "<center><em><sub>─────── End Of Section ───────</sub></em></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
